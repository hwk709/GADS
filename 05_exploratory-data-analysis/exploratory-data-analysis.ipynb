{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas for Exploratory Data Analysis\n",
    "\n",
    "_Author: Kevin Markham (Washington, D.C.)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- Define what Pandas is and how it relates to data science.\n",
    "- Manipulate Pandas `DataFrames` and `Series`.\n",
    "- Filter and sort data using Pandas.\n",
    "- Manipulate `DataFrame` columns.\n",
    "- Know how to handle null and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "\n",
    "- [What Is Pandas?](#pandas)\n",
    "- [Reading Files, Selecting Columns, and Summarizing](#reading-files)\n",
    "    - [Exercise 1](#exercise-one)\n",
    "    \n",
    "    \n",
    "- [Filtering and Sorting](#filtering-and-sorting)\n",
    "    - [Exercise 2](#exercise-two)\n",
    "    \n",
    "    \n",
    "- [Renaming, Adding, and Removing Columns](#columns)\n",
    "- [Handling Missing Values](#missing-values)\n",
    "    - [Exercise 3](#exercise-three)\n",
    "    \n",
    "    \n",
    "- [Split-Apply-Combine](#split-apply-combine)\n",
    "    - [Exercise 4](#exercise-four)\n",
    "    \n",
    "    \n",
    "- [Selecting Multiple Columns and Filtering Rows](#multiple-columns)\n",
    "- [Joining (Merging) DataFrames](#joining-dataframes)\n",
    "- [OPTIONAL: Other Commonly Used Features](#other-features)\n",
    "- [OPTIONAL: Other Less Used Features of Pandas](#uncommon-features)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pandas\"></a>\n",
    "\n",
    "## What Is Pandas?\n",
    "\n",
    "- **Objective:** Define what Pandas is and how it relates to data science.\n",
    "\n",
    "Pandas is a Python library that primarily adds two new datatypes to Python: `DataFrame` and `Series`.\n",
    "\n",
    "- **Series** == sequence of items, where each item has a unique label (called an index).\n",
    "- **DataFrame** == a table of data. Each row has a unique label (the row index), and each column has a unique label (the column index).\n",
    "- Note that each column in a DataFrame can be considered a Series (Series index).\n",
    "\n",
    "Behind the scenes, these datatypes use **NumPy (\"Numerical Python\")**.\n",
    "\n",
    "- NumPy primarily adds the ndarray (n-dimensional array) datatype to Pandas.\n",
    "- An ndarray is similar to a Python list — it stores ordered data.\n",
    "- Storing Series and DataFrame data in ndarrays makes Pandas faster and uses less memory than standard Python datatypes. Many libraries (such as scikit-learn) accept ndarrays as input rather than Pandas datatypes, so we will frequently convert between them.\n",
    "\n",
    "### Using Pandas\n",
    "\n",
    "Pandas is frequently used in data science because:\n",
    "\n",
    "- Offers a large set of commonly used functions\n",
    "- Fast processing\n",
    "- Large developer community.\n",
    "- Because many data science libraries also use NumPy to manipulate data, you can easily transfer data between libraries (as we will often do in this class!).\n",
    "- Pandas is a large library.\n",
    "\n",
    "- It heavily overrides Python operators, resulting in different syntax.\n",
    "\n",
    "- Looping through a DataFrame row by row is highly discouraged. Instead, Pandas favors using vectorized functions that operate column by column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Methods and Attributes\n",
    "\n",
    "Pandas `DataFrame`s are Pandas class objects and therefore come with attributes and methods. To access these, follow the variable name with a dot. For example, given a `DataFrame` called `users`:\n",
    "\n",
    "```\n",
    "- users.index       # accesses the `index` attribute -- note there are no parentheses. attributes are not callable\n",
    "- users.head()      # calls the `head` method (since there are open/closed parentheses)\n",
    "- users.head(10)    # calls the `head` method with parameter `10`, indicating the first 10 rows. this is the same as:\n",
    "- users.head(n=10)  # calls the `head` method, setting the named parameter `n` to have a value of `10`.\n",
    "```\n",
    "\n",
    "We know that the `head` method accepts one parameter with an optional name of `n` because it is in the documentation for that method. Let's see how to view the documentation next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Documentation\n",
    "\n",
    "There are a few ways to find more information about a method.\n",
    "\n",
    "**Method 1:** In Jupyter, you can quickly view documentation for a method by following the method name by a `?`, as follows:\n",
    "\n",
    "```\n",
    "users.head?\n",
    "```\n",
    "\n",
    "> ```\n",
    "Signature: users.head(n=5)\n",
    "Docstring: Returns first n rows\n",
    "```\n",
    "\n",
    "Notice that we would normally invoke this method by calling `users.head(5)`. One quirk of IPython is that the `?` symbol must be the last character in the cell. Otherwise, it might not work.\n",
    "\n",
    "> The `?` is a shortcut for the built-in Python function `help`, which returns the method's docstring. For example:\n",
    "> ```\n",
    "help(users.head)\n",
    "```\n",
    "\n",
    "**Method 2:** You can also search online for the phrase \"`DataFrame head`\", since you are calling the method `head` on the `users` object, which happens to be a `DataFrame`. (`type(users) => pandas.DataFrame`)\n",
    "\n",
    "You can alternatively search online for `pandas head`, but be careful! `DataFrame` and `Series` both have a `head` method, so make sure you view the documentation for the correct one since they might be called differently. You will know you are looking at the correct documentation page because it will say `DataFrame.head` at the top, instead of `Series.head`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pandas into Python\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see the details about the imported package by referencing its private class propertys:\n",
    "# We want to know what version our package is, because things change.\n",
    "print(pd.__name__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick aside - what is a magic function? Let's find out - Today we're going to spend a bit of time learning to use documentation\n",
    "#try running this\n",
    "\n",
    "%magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magic Functions in Jupyter\n",
    "\n",
    "IPython (the jupyter shell) has a set of predefined ‘magic functions’ that you can call with a command line style syntax. There are two kinds of magics, line-oriented and cell-oriented. Line magics are prefixed with the % character and work much like OS command-line calls: they get as an argument the rest of the line, where arguments are passed without parentheses or quotes. Cell magics are prefixed with a double %%, and they are functions that get as an argument not only the rest of the line, but also the lines below it in a separate argument.\n",
    "\n",
    "[Learn More](https://ipython.readthedocs.io/en/stable/interactive/magics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reading-files\"></a>\n",
    "### Reading Files, Selecting Columns, and Summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dramatically simplifies the process of reading in data. When we say \"reading in data,\" we mean loading a file into our machine's memory.\n",
    "\n",
    "When you have a CSV, for example, and then you double-click to open it in Microsoft Excel, the open file is \"read into memory.\" You can now manipulate the CSV.\n",
    "\n",
    "When we read data into memory in Python, we are creating an object. We will soon explore this object.\n",
    "\n",
    "Because we are working with a tbl, we will use the [read table](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html) method.\n",
    "<br>\n",
    "<br>\n",
    "A [delimiter](https://en.wikipedia.org/wiki/Delimiter-separated_values) is a character that separates fields (columns) in the imported file. Just because a file says `.csv` does not necessarily mean that a comma is used as the delimiter. In this case, we have a pipe character as the delimiter for our columns, so we will be using `sep='|'` to tell pandas to 'cut' the columns every time it sees a pipe character in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./data/user.tbl', sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examine the users data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users                   # Print the first 30 and last 30 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(users)             # DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()            # Print the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(10)          # Print the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.tail()            # Print the last five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # The row index (aka \"the row labels\" — in this case integers)\n",
    "users.index     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names (which is \"an index\")\n",
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatypes of each column — each column is stored as an ndarray, which has a datatype\n",
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows and columns\n",
    "users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classroom Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows as an int\n",
    "\n",
    "\n",
    "#number of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All values as a NumPy array\n",
    "users.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concise summary (including memory usage) — useful to quickly see if nulls exist\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select or index data.**<br>\n",
    "Pandas `DataFrame`s have structural similarities with Python-style lists and dictionaries.  \n",
    "In the example below, we select a column of data using the name of the column in a similar manner to how we select a dictionary value with the dictionary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column — returns a Pandas Series (essentially an ndarray with an index)\n",
    "users['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns are Pandas Series.\n",
    "type(users['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column using the DataFrame attribute.\n",
    "users.gender\n",
    "\n",
    "# While a useful shorthand, these attributes only exist\n",
    "# if the column name has no punctuations or spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summarize (describe) the data.**<br>\n",
    "Pandas has a bunch of built-in methods to quickly summarize your data and provide you with a quick general understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all numeric columns.\n",
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all object columns (can include multiple types).\n",
    "users.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all columns, including non-numeric.\n",
    "users.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe a single column — recall that \"users.gender\" refers to a Series.\n",
    "users.gender.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the ages.\n",
    "users.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a histogram of a column (the distribution of ages).\n",
    "users.age.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of occurrences of each value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.occupation.value_counts()     # Most useful for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.occupation.value_counts().plot(kind='barh')     # Quick plot by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be used with numeric variables\n",
    "#   Try .sort_index() to sort by indices or .sort_values() to sort by counts.\n",
    "users.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.age.value_counts().sort_index().plot(kind='bar', figsize=(12,12));     # Bigger plot by increasing age\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Number of users');\n",
    "plt.title('Number of users per age');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unique values:** Determine the number of distinct values within a given series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the unique occupations?\n",
    "users['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW MANY distinct occupations are there?\n",
    "users['occupation'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Summary: Combining What We Have Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize our dataset \n",
    "print (\"Rows     : \" ,users.shape[0])\n",
    "print (\"Columns  : \" ,users.shape[1])\n",
    "print (\"\\nFeatures : \\n\" ,users.columns.tolist())\n",
    "print (\"\\nMissing values :  \", users.isnull().sum().values.sum())\n",
    "print (\"\\nUnique values :  \\n\",users.nunique())\n",
    "\n",
    "print(\"\\nFirst 5 Rows :  \\n\",users.head())\n",
    "\n",
    "print(\"\\nLast 5 Rows :  \\n\",users.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-one\"></a>\n",
    "### Exercise 1: Drinks Across the World\n",
    "\n",
    "Because we are working with a CSV, we will use the [read CSV](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) method.<br>A [delimiter](https://en.wikipedia.org/wiki/Delimiter-separated_values) is a character that separates fields (columns) in the imported file. Just because a file says `.csv` does not necessarily mean that a comma is used as the delimiter. In this case, we have a tab character as the delimiter for our columns, so we will be using `sep='\\t'` to tell pandas to 'cut' the columns every time it sees a [tab character in the file](http://vim.wikia.com/wiki/Showing_the_ASCII_value_of_the_current_character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read drinks.csv into a DataFrame called \"drinks\".\n",
    "# Path to csv './data/drinks.csv'\n",
    "\n",
    "drinks = pd.read_csv('./data/drinks.csv', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head and the tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the default index, datatypes, and shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the beer_servings Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average beer_servings for the entire data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each \"continent\" value and see if it looks correct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Columns\n",
    "\n",
    "We can select columns in two ways. Either we treat the column as an attribute of the DataFrame or we index the DataFrame for a specific element (in this case, the element is a column name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show difference between single (Series) and double (DataFrame) bracket notation\n",
    "#Dataframe\n",
    "drinks[['country','wine_servings']]\n",
    "\n",
    "#Series\n",
    "#drinks['country']\n",
    "drinks.country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classroom Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the country column, Series object\n",
    "#drinks.country\n",
    "drinks['country'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the country column, DataFrame object\n",
    "drinks[['country', 'wine_servings']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:** selecting > 1 column (must use double brackets!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering-and-sorting\"></a>\n",
    "### Filtering and Sorting\n",
    "\n",
    "Filtering and sorting are key processes that allow us to drill into the 'nitty gritty' and cross sections of our dataset.\n",
    "\n",
    "To filter, we use a process called **Boolean Filtering**, wherein we define a Boolean condition, and use that Boolean condition to filter on our DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering: Only show users with age < 20.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying a `boolean mask` to this dataframe, `age < 20`, we can get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series of Booleans…\n",
    "# In Pandas, this comparison is performed element-wise on each row of data.\n",
    "young_bool = users.age < 20\n",
    "#young_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# …and use that Series to filter rows.\n",
    "# In Pandas, indexing a DataFrame by a Series of Booleans only selects rows that are True in the Boolean.\n",
    "users[young_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, combine into a single step.\n",
    "#users[users.gender == 'F']\n",
    "\n",
    "users_noother= users[users.occupation != 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_noother.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: This creates a view of the original DataFrame, not a new DataFrame.\n",
    "# If you alter this view (e.g., by storing it in a variable and altering that)\n",
    "# You will alter only the slice of the DataFrame and not the actual DataFrame itself\n",
    "# Here, notice that Pandas gives you a SettingWithCopyWarning to alert you of this.\n",
    "\n",
    "# It is best practice to use .loc and .iloc instead of the syntax below\n",
    "\n",
    "users_under20 = users[users.age < 20].copy()   # To resolve this warning, copy the `DataFrame` using `.copy()`.\n",
    "users_under20['newcolumn'] = 0\n",
    "users_under20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one column from the filtered results.\n",
    "users[users.age < 20][['occupation']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts of resulting Series\n",
    "users[users.age < 20].occupation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logical filtering with multiple conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ampersand for `AND` condition. (This is a \"bitwise\" `AND`.)\n",
    "# Important: You MUST put parentheses around each expression because `&` has a higher precedence than `<`.\n",
    "users[(users.age <20) & (users.gender=='F')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe for `OR` condition. (This is a \"bitwise\" `OR`.)\n",
    "# Important: You MUST put parentheses around each expression because `|` has a higher precedence than `<`.\n",
    "users[((users.age < 20) | (users.age > 60)) & (users.gender=='M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferred alternative to multiple `OR` conditions\n",
    "#users[((users.occupation =='doctor') | (users.occupation =='lawyer') | (users.occupation =='programmer'))]\n",
    "user_doclaw = users[users.occupation.isin(['doctor', 'lawyer','programmer'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_doclaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a Series.\n",
    "users.age.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a DataFrame by a single column.\n",
    "users.sort_values('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use descending order instead.\n",
    "users.sort_values('age', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by multiple columns.\n",
    "users.sort_values(['occupation', 'age'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-two\"></a>\n",
    "### Exercise 2: Filtered Drinks\n",
    "Use the `drinks.csv` or `drinks` `DataFrame` from earlier to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to only include European countries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame to only include European countries with wine_servings > 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average beer_servings for all of Europe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which 10 countries have the highest total_litres_of_pure_alcohol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"columns\"></a>\n",
    "### Renaming, Adding, and Removing Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we want to rename our columns. There are a few options for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are beer servings and spirit servings correlated?\n",
    "drinks.plot(kind='scatter', x='beer_servings', y='spirit_servings');\n",
    "\n",
    "print((drinks.corr()['beer_servings']))  # Correlation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming **specific** columns by using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns in a single output using value mapping.\n",
    "drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns in the original DataFrame.\n",
    "drinks.rename(columns={'beer_servings':'beer', 'wine_servings':'wine'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace all column names using a list of matching length.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace during file reading (disables the header from the file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of matching length\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'litres','continent'] \n",
    "\n",
    "# Read in data with new columns\n",
    "drinks = pd.read_csv('data/drinks.csv', header=0, names=drink_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace after file has already been read into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of matching length\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'liters', 'cont'] \n",
    "\n",
    "# Replace after file has already been read into Python.\n",
    "drinks.columns = drink_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list functions to modify your list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink_cols.pop()\n",
    "drink_cols.append('continent')\n",
    "\n",
    "drinks.columns = drink_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use list indexing to mutate the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutate list\n",
    "drink_cols[0]='Country'\n",
    "drink_cols[4]='ltrs'\n",
    "\n",
    "\n",
    "drinks.columns = drink_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easy Column Operations**<br>\n",
    "Rather than having to reference indexes and create for loops to do column-wise operations, Pandas is smart and knows that when we add columns together we want to add the values in each row together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column as a function of existing columns.\n",
    "drinks['servings'] = drinks.beer + drinks.spirit + drinks.wine\n",
    "drinks['mL'] = drinks.ltrs * 1000\n",
    "\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=0 for rows, 1 for columns\n",
    "drinks.drop('mL', axis=1)\n",
    "drinks.drop(5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop multiple columns.\n",
    "drinks.drop(['mL', 'servings'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop on the original DataFrame rather than returning a new one.\n",
    "drinks.drop(['mL', 'servings'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.drop(5, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-values\"></a>\n",
    "### Handling Missing Values\n",
    "\n",
    "- **Objective:** Know how to handle null and missing values.\n",
    "\n",
    "Sometimes, values will be missing from the source data or as a byproduct of manipulations. It is very important to detect missing data. Missing data can:\n",
    "\n",
    "- Make the entire row ineligible to be training data for a model.\n",
    "- Hint at data-collection errors.\n",
    "- Indicate improper conversion or manipulation.\n",
    "- Actually not be missing — it sometimes means \"zero,\" \"false,\" \"not applicable,\" or \"entered an empty string.\"\n",
    "\n",
    "For example, a `.csv` file might have a missing value in some data fields:\n",
    "\n",
    "```\n",
    "tool_name,material,cost\n",
    "hammer,wood,8\n",
    "chainsaw,,\n",
    "wrench,metal,5\n",
    "```\n",
    "\n",
    "When this data is imported, \"null\" values will be stored in the second row (in the \"material\" and \"cost\" columns).\n",
    "\n",
    "> In Pandas, a \"null\" value is either `None` or `np.NaN` (Not a Number). Many fixed-size numeric datatypes (such as integers) do not have a way of representing `np.NaN`. So, numeric columns will be promoted to floating-point datatypes that do support it. For example, when importing the `.csv` file above:\n",
    "\n",
    "> - **For the second row:** `None` will be stored in the \"material\" column and `np.NaN` will be stored in the \"cost\" column. The entire \"cost\" column (stored as a single `ndarray`) must be stored as floating-point values to accommodate the `np.NaN`, even though an integer `8` is in the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values are usually excluded in calculations by default.\n",
    "drinks.continent.value_counts()              # Excludes missing values in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Includes missing values\n",
    "drinks.continent.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in a Series.\n",
    "# True if missing, False if not missing\n",
    "drinks.continent.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the missing values — sum() works because True is 1 and False is 0.\n",
    "drinks.continent.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if not missing, False if missing\n",
    "drinks.continent.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show rows where continent is not missing.\n",
    "drinks[drinks.continent.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Pandas Axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"down\" the 0 axis (rows) — so, we get the sums of each column\n",
    "drinks.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis=0 is the default.\n",
    "drinks.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sums \"across\" the 1 axis (columns) — so, we get the sums of numeric values in the row (beer+spirit+wine+liters+…)\n",
    "drinks['totalsum']=drinks.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find missing values in a `DataFrame`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of Booleans\n",
    "drinks.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the missing values in each column — remember by default, axis=0.\n",
    "print((drinks.isnull().sum()))\n",
    "\n",
    "drinks.isnull().sum().plot(kind='bar');         # visually\n",
    "plt.title('Number of null values per column');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row if ANY values are missing from any column — can be dangerous!\n",
    "drinks.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row only if ALL values are missing.\n",
    "drinks.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check missing values are gone\n",
    "drinks[drinks.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling Missing Values**<br>\n",
    "You may have noticed that the continent North America (NA) does not appear in the `continent` column. Pandas read in the original data and saw \"NA\", thought it was a missing value, and converted it to a `NaN`, missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of matching length\n",
    "drink_cols = ['country', 'beer', 'spirit', 'wine', 'litres','continent'] \n",
    "\n",
    "# Read in data with new columns\n",
    "drinks = pd.read_csv('data/drinks.csv', header=0, names=drink_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values with \"NA\" — this is dangerous to do without manually verifying them!\n",
    "drinks.continent.fillna(value='Island')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifies \"drinks\" in-place\n",
    "drinks.continent.fillna(value='Island', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the missing value filter — this is a better approach!\n",
    "drinks = pd.read_csv('./data/drinks.csv', header=0, names=drink_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-three\"></a>\n",
    "### Exercise 3: UF-uh oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ufo.csv into a DataFrame called \"ufo\".\n",
    "ufo_data = './data/ufo.csv'\n",
    "ufo = pd.read_csv(ufo_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the three most common colors reported?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename any columns with spaces so that they don't contain spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking your work is a great step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reports in VA, what's the most common city?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a DataFrame containing only reports from Arlington, VA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values in each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows remain if you drop all rows with any missing values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows did we lose by removing all rows with any missing values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split-apply-combine\"></a>\n",
    "### Split-Apply-Combine\n",
    "\n",
    "Split-apply-combine is a pattern for analyzing data. Suppose we want to find mean beer consumption per country. Then:\n",
    "\n",
    "- **Split:** We group data by continent.\n",
    "- **Apply:** For each group, we apply the `mean()` function to find the average beer consumption.\n",
    "- **Combine:** We now combine the continent names with the `mean()`s to produce a summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, calculate the mean beer servings.\n",
    "drinks.groupby('continent').beer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, calculate the mean of all numeric columns.\n",
    "drinks.groupby('continent').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, describe beer servings.\n",
    "drinks.groupby(['continent','country']).beer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar, but outputs a DataFrame and can be customized — \"agg\" allows you to aggregate results of Series functions\n",
    "#drinks.groupby('continent').beer.agg(['count', 'mean', 'min', 'max'])\n",
    "drinks.groupby('continent').beer.agg(['count','min', 'max']).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, describe all numeric columns.\n",
    "drinks.groupby('continent').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each continent, count the number of rows.\n",
    "#print((drinks.groupby('continent').continent.count()))\n",
    "#print((drinks.continent.value_counts()))   # should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercise-four\"></a>\n",
    "### Exercise 4: Users\n",
    "\n",
    "Use the \"users\" `DataFrame` or \"users\" file in the Data folder to complete the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation in \"users\", count the number of occurrences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation, calculate the mean age.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each occupation, calculate the minimum and maximum ages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each combination of occupation and gender, calculate the mean age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"multiple-columns\"></a>\n",
    "### Selecting Multiple Columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns — yet another overload of the DataFrame indexing operator!\n",
    "my_cols = ['city', 'state']     # Create a list of column names...\n",
    "ufo[my_cols]                    # ...and use that list to select columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo[['City', 'State']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, combine into a single step (this is a Python list inside of the Python index operator!).\n",
    "ufo[['City', 'State']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `loc` to select columns by name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"loc\" locates the values from the first parameter (colon means \"all rows\"), and the column \"City\".\n",
    "ufo.loc[:, 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two columns.\n",
    "ufo.loc[:, ['city', 'state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a range of columns — unlike Python ranges, Pandas index ranges INCLUDE the final column in the range.\n",
    "ufo.loc[:, 'city':'shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"loc\" can also filter rows by \"name\" (the index).\n",
    "# Row 0, all columns\n",
    "ufo.loc[1, 'city':'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 0/1/2, all columns\n",
    "ufo.loc[0:10, 'city':'shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 0/1/2, range of columns\n",
    "ufo.loc[0:2, 'City':'State'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"iloc\" to filter rows and select columns by integer position.\n",
    "# (Remember that rows/columns use indices, so \"iloc\" lets you refer to indices via their index rather than value!)\n",
    "# All rows, columns in position 0/3 (City/State)\n",
    "ufo.iloc[:, [0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows, columns in position 0/1/2/3\n",
    "# Note here it is NOT INCLUDING 4 because this is an integer range, not a Pandas index range!\n",
    "ufo.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows in position 0/1/2, all columns\n",
    "ufo.iloc[0:3, 2:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"joining-dataframes\"></a>\n",
    "### Joining (Merging) `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "movie_cols = ['movie_id', 'title']\n",
    "movies_filename = './data/movies.tbl'\n",
    "\n",
    "movies = pd.read_table(movies_filename, sep='|', header=None, names=movie_cols, usecols=[0, 1], encoding='latin1')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings_filename = './data/movie_ratings.tsv'\n",
    "\n",
    "ratings = pd.read_table(ratings_filename, sep='\\t', header=None, names=rating_cols)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \"movies\" and \"ratings\" (inner join on \"movie_id\").\n",
    "movie_ratings = pd.merge(movies, ratings)\n",
    "movie_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "print(ratings.shape)\n",
    "print(movie_ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other-features\"></a>\n",
    "### OPTIONAL: Other Commonly Used Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an arbitrary function to each value of a Pandas column, storing the result in a new column.\n",
    "users['under30'] = users.age.apply(lambda age: age < 30)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an arbitrary function to each row of a DataFrame, storing the result in a new column.\n",
    "#  (Remember that, by default, axis=0. Since we want to go row by row, we set axis=1.)\n",
    "\n",
    "users['under30male'] = users.apply(lambda row: row.age < 30 and row.gender == 'M', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map existing values to a different set of values.\n",
    "users['is_male'] = users.gender.map({'F':0, 'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all instances of a value in a column (must match entire value).\n",
    "ufo.State.replace('Fl', 'FL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String methods are accessed via \"str\".\n",
    "ufo.State.str.upper()                               # Converts to upper case\n",
    "# checks for a substring\n",
    "ufo['Colors'].str.contains('RED', na='False') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string to the datetime format (this is often slow — consider doing it in the \"read_csv()\" method.)\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "ufo.Time.dt.hour                        # Datetime format exposes convenient attributes\n",
    "(ufo.Time.max() - ufo.Time.min()).days  # Also allows you to do datetime \"math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and then remove an index.\n",
    "ufo.set_index('Time', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of a column.\n",
    "drinks['beer'] = drinks.beer.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for \"continent\" and exclude first dummy column.\n",
    "continent_dummies = pd.get_dummies(drinks.continent, prefix='cont').iloc[:, 1:]\n",
    "continent_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two DataFrames (axis=0 for rows, axis=1 for columns).\n",
    "drinks = pd.concat([drinks, continent_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"uncommon-features\"></a>\n",
    "### OPTIONAL: Other Less-Used Features of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting duplicate rows\n",
    "users.duplicated()          # True if a row is identical to a previous row\n",
    "users.duplicated().sum()    # Count of duplicates\n",
    "users[users.duplicated()]   # Only show duplicates\n",
    "users.drop_duplicates()     # Drop duplicate rows\n",
    "users.age.duplicated()      # Check a single column for duplicates\n",
    "users.duplicated(['age', 'gender', 'zip_code']).sum()   # Specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a range of values into descriptive groups.\n",
    "drinks['beer_level'] = 'low'    # Initially set all values to \"low\"\n",
    "drinks.loc[drinks.beer.between(101, 200), 'beer_level'] = 'med'     # Change 101-200 to \"med\"\n",
    "drinks.loc[drinks.beer.between(201, 400), 'beer_level'] = 'high'    # Change 201-400 to \"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a cross-tabulation of two Series.\n",
    "pd.crosstab(drinks.continent, drinks.beer_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"beer_level\" into the \"category\" datatype.\n",
    "drinks['beer_level'] = pd.Categorical(drinks.beer_level, categories=['low', 'med', 'high'])\n",
    "drinks.sort_values('beer_level')   # Sorts by the categorical ordering (low to high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit which rows are read when reading in a file — useful for large files!\n",
    "pd.read_csv('./data/drinks.csv', nrows=10)           # Only read first 10 rows\n",
    "pd.read_csv('./data/drinks.csv', skiprows=[1, 2])    # Skip the first two rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a DataFrame out to a .csv\n",
    "drinks.to_csv('drinks_updated.csv')                 # Index is used as first column\n",
    "drinks.to_csv('drinks_updated.csv', index=False)    # Ignore index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary.\n",
    "pd.DataFrame({'capital':['Montgomery', 'Juneau', 'Phoenix'], 'state':['AL', 'AK', 'AZ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a list of lists.\n",
    "pd.DataFrame([['Montgomery', 'AL'], ['Juneau', 'AK'], ['Phoenix', 'AZ']], columns=['capital', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a DataFrame.\n",
    "import numpy as np\n",
    "mask = np.random.rand(len(drinks)) < 0.66   # Create a Series of Booleans\n",
    "train = drinks[mask]                        # Will contain around 66% of the rows\n",
    "test = drinks[~mask]                        # Will contain the remaining rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the maximum number of rows and columns printed ('None' means unlimited).\n",
    "pd.set_option('max_rows', None)     # Default is 60 rows\n",
    "pd.set_option('max_columns', None)  # Default is 20 columns\n",
    "print(drinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset options to defaults.\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the options temporarily (settings are restored when you exit the \"with\" block).\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print(drinks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "### Summary\n",
    "\n",
    "Believe it or not, we've only barely touched the surface of everything that Pandas offers. Don't worry if you don't remember most of it — for now, just knowing what exists is key. Remember that the more you use Pandas to manipulate data, the more of these functions you will take interest in, look up, and remember.\n",
    "\n",
    "In this notebook, the most important things to familiarize yourself with are the basics:\n",
    "- Manipulating `DataFrames` and `Series`\n",
    "- Filtering columns and rows\n",
    "- Handling missing values\n",
    "- Split-apply-combine (this one takes some practice!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "We covered a lot of ground! It's ok if this takes a while to gel.\n",
    "\n",
    "```python\n",
    "\n",
    "# basic DataFrame operations\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "df.columns\n",
    "df.Index\n",
    "\n",
    "# selecting columns\n",
    "df.column_name\n",
    "df['column_name']\n",
    "\n",
    "# renaming columns\n",
    "df.rename({'old_name':'new_name'}, inplace=True)\n",
    "df.columns = ['new_column_a', 'new_column_b']\n",
    "\n",
    "# notable columns operations\n",
    "df.describe() # five number summary\n",
    "df.column_name.nunique() # number of unique values\n",
    "df.column_name.value_counts() # number of occurrences of each value in column\n",
    "\n",
    "# filtering\n",
    "df[df.column_name < 50] # filter column to be less than 50\n",
    "\n",
    "# sorting\n",
    "df.sort_values(by='column_name', ascending = False) # sort biggest to smallest\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "It's common to refer back to your own code *all the time.* Don't hesistate to reference this guide! 🐼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
